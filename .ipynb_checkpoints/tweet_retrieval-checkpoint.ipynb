{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "#rom Events_NER.EventSegmentClusterer import get_events, get_seg_similarity\n",
    "#rom Events_NER.TimeWindow import TimeWindow\n",
    "#from Events_NER.TwitterEventDetector import TwitterEventDetector\n",
    "from Events_NER.TweetSegmenter import SEDTWikSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet Startd\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Status' object has no attribute 'full_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-42f18118f23f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretweeted_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Status' object has no attribute 'extended_tweet'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-42f18118f23f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretweeted_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretweeted_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Status' object has no attribute 'full_text'"
     ]
    }
   ],
   "source": [
    "####input your credentials here\n",
    "consumer_key = '95cMtk1vJvEEW2rlMR0kIU9lE'\n",
    "consumer_secret = 'pMQFi7LBdcudKDNZOokUJGS8mDxQanUv8spxBDdTLiwSZBuUOM'\n",
    "access_token = '1036313393114767360-BZ8Qpi02ghRvehhcITEIyl7SmGWmU6'\n",
    "access_token_secret = 'C7VAqGDhTdB424iBtEwF1CJI9YPTcvNvLjFmaCXENNv3G'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "#####United Airlines\n",
    "# Open/Create a file to append data\n",
    "csvFile = open('ua.csv', 'a')\n",
    "#Use csv Writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for status in tweepy.Cursor(api.search,q=\"#blacklivesmatter\",count=1,\n",
    "                           lang=\"en\",\n",
    "                           since=\"2017-04-03\").items():\n",
    "    print(\"Tweet Startd\")\n",
    "    if hasattr(status, \"retweeted_status\"):  # Check if Retweet\n",
    "        try:\n",
    "            print(status.retweeted_status.extended_tweet[\"full_text\"])\n",
    "        except AttributeError:\n",
    "            print(status.retweeted_status.full_text)\n",
    "    else:\n",
    "        try:\n",
    "            print(status.extended_tweet[\"full_text\"])\n",
    "        except AttributeError:\n",
    "            print(status.full_text)\n",
    "    #print(status.parse())\n",
    "    print(\"Tweet Ended\")\n",
    "    #csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SEDTWik Segmenter\n",
      "SEDTWik Segmenter Ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wiki_titles_file = \"Events_NER/data/final.txt\"\n",
    "segmenter = SEDTWikSegmenter(wiki_titles_file, 4, 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet():\n",
    "    \n",
    "    def __init__(self, status_response):\n",
    "        self.id = status_response.id\n",
    "        #self._get_text(status_response)\n",
    "        self.user_info = status_response.user\n",
    "        self.entitites = status_response.entities\n",
    "        self.json = status_response._json\n",
    "        arr = []\n",
    "        for users in self.json['entities']['user_mentions']: \n",
    "            arr += [users['name']]\n",
    "        self.json['entities']['user_mentions'] = arr\n",
    "        arr = []\n",
    "        for users in self.json['entities']['hashtags']: \n",
    "            arr += [users['text']]\n",
    "        self.json['entities']['hashtags'] = arr\n",
    "        \n",
    "    def _get_text(self, status):\n",
    "        if hasattr(status, \"retweeted_status\"):  # Check if Retweet\n",
    "            try:\n",
    "                self.text = status.retweeted_status.extended_tweet[\"full_text\"]\n",
    "            except AttributeError:\n",
    "                self.text = status.retweeted_status.full_text\n",
    "        else:\n",
    "            try:\n",
    "                self.text = status.extended_tweet[\"full_text\"]\n",
    "            except AttributeError:\n",
    "                self.text = status.full_text\n",
    "    \n",
    "    #code for generating named entities of each tweet\n",
    "    def _get_named_entities(self):\n",
    "        return segmenter.tweet_segmentation(self.json)\n",
    "        \n",
    "    #code for generating event phrases\n",
    "    def _get_event_phrases(self):\n",
    "        return []\n",
    "    \n",
    "    def get_graph_entities(self):\n",
    "        return self._get_named_entities() + self._get_event_phrases()\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self.id\n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id\n",
    "    \n",
    "class TweetRetriever():\n",
    "\n",
    "    def __init__(self):\n",
    "        consumer_key = '95cMtk1vJvEEW2rlMR0kIU9lE'\n",
    "        consumer_secret = 'pMQFi7LBdcudKDNZOokUJGS8mDxQanUv8spxBDdTLiwSZBuUOM'\n",
    "        access_token = '1036313393114767360-BZ8Qpi02ghRvehhcITEIyl7SmGWmU6'\n",
    "        access_token_secret = 'C7VAqGDhTdB424iBtEwF1CJI9YPTcvNvLjFmaCXENNv3G'\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self.api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "    \n",
    "    def getTweets(self, hashtag, count = 10):\n",
    "        tweets = []\n",
    "        for status in tweepy.Cursor(self.api.search, q = hashtag, count = count, \n",
    "                                    lang = 'en').items():\n",
    "            tweets.append(Tweet(status))\n",
    "        return tweets\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNode():\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.tweeets = set()\n",
    "        self.value = 0\n",
    "        \n",
    "    def add_tweet(self, tweet):\n",
    "        self.tweeets.add(tweet)\n",
    "    \n",
    "    def common_tweets(self, other):\n",
    "        return len(self.tweeets.intersection(other.tweets))\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self.name\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name\n",
    "    \n",
    "class TweetGraph():\n",
    "    \n",
    "    def __init__(self, topic):\n",
    "        self.topic = topic\n",
    "        self.nodes = {}\n",
    "        self.edge_map = {}\n",
    "        \n",
    "    def add_entity(self, name, tweet_ref):\n",
    "        if name not in nodes:\n",
    "            nodes[name] = GraphNode(name)\n",
    "        nodes[name].add_tweet(tweet_ref)\n",
    "    \n",
    "    def add_edge(self, node1, node2):\n",
    "        assert node1.name in self.node_map\n",
    "        assert node2.name in self.node_map\n",
    "        weight = node1.common_tweets(node2)\n",
    "        self.edge_map.setdefault(node1.name, {}).setdefault(node2.name, weight)\n",
    "        self.edge_map.setdefault(node2.name, {}).setdefault(node1.name, weight)\n",
    "    \n",
    "    def compute_all_edges(self):\n",
    "        for node1 in self.nodes.values():\n",
    "            for node2 in self.nodes.values():\n",
    "                self.add_edge(node1, node2)\n",
    "    \n",
    "    def _get_pagerank_matrix(self):\n",
    "        x = [[0 for _ in len(self.nodes)] for _ in len(self.nodes)]\n",
    "        for i, node1 in enumerate(self.nodes.values()):\n",
    "            wsum = 0\n",
    "            for node2 in self.nodes.values():\n",
    "                wsum += self.edge_map.get(node1.name, {}).get(node2.name, 0)\n",
    "            for j, node2 in enumerate(self.nodes.values()):\n",
    "                x[i][j] = self.edge_map.get(node1.name, {}).get(node2.name, 0)/wsum\n",
    "        return np.array(x)\n",
    "    \n",
    "    def set_textrank_values(self, d = 0.85):\n",
    "        rank_graph = nx.from_numpy_array(self._get_pagerank_matrix())\n",
    "        node_scores = nx.pagerank(rank_graph, aplpha = d)\n",
    "        for i, node in enumerate(self.nodes.values()):\n",
    "            node.value = node_scores[i]\n",
    "    \n",
    "    def get_weight(self, node1, node2):\n",
    "        return self.edge_map(node1.name, {}).get(node2.name, 0)\n",
    "    \n",
    "    def get_topic_similarity(self, node):\n",
    "        if node.name in self.topic:\n",
    "            return len(node.tweeets)\n",
    "        return 1\n",
    "    \n",
    "    def get_nodes_above_thres(self, thres = 1):\n",
    "        nodes = []\n",
    "        value_sum = 0\n",
    "        for node in self.nodes.values():\n",
    "            if node.value > thres:\n",
    "                nodes.append(node)\n",
    "                value_sum += node.value\n",
    "        return nodes, value_sum\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraph(topic, tweets):\n",
    "    tweetGraph = TweetGraph(topic)\n",
    "    for tweet in tweets:\n",
    "        graph_entities = tweet.get_graph_entities()\n",
    "        for name in graph_entities:\n",
    "            tweetGraph.add_entity(name, tweet)\n",
    "    tweetGraph.compute_all_edges()\n",
    "    tweetGraph.set_textrank_values()\n",
    "    return tweetGraph\n",
    "\n",
    "def partitionGraph(tweetGraph, alpha, beta, high_rank_thres = 1):\n",
    "    \n",
    "    #initialize highly ranked nodes and their total values sum\n",
    "    high_ranked_nodes, total_value_sum = tweetGraph.get_nodes_above_thres(high_rank_thres)\n",
    "    high_ranked_nodes = sorted(high_ranked_nodes, key = lambda x: x.value)\n",
    "    partitions = []\n",
    "    \n",
    "    #partitioning loop\n",
    "    while len(high_ranked_nodes):\n",
    "        #entity set is the nodes in the partition\n",
    "        entity_set = set()\n",
    "        repr_node = high_ranked_nodes.pop()\n",
    "        entitiy_set.add(repr_node)\n",
    "        repr_node_topic_similarity = tweetGraph.get_topic_similarity(repr_node)\n",
    "        value_sum = repr_node.value\n",
    "        \n",
    "        for node in high_ranked_nodes:\n",
    "            node_edge_weight = tweetGraph.get_weight(repr_node, node)\n",
    "            node_topic_similarity = tweetGraph.get_topic_similarity(node)\n",
    "            \n",
    "            if node_edge_weight/repr_node_topic_similarity > alpha and \\\n",
    "                node_topic_similarity/repr_node_topic_similarity > alpha:\n",
    "                entity_set.add(node)\n",
    "                value_sum += node.value\n",
    "        \n",
    "        if value_sum/total_value_sum > beta:\n",
    "            temp = []\n",
    "            for node in high_ranked_nodes:\n",
    "                if node not in entitiy_set:\n",
    "                    temp.append(node)\n",
    "            high_ranked_nodes = temp\n",
    "            \n",
    "        partitions.append([])\n",
    "        for node in list(entity_set):\n",
    "            partitions[-1].append(node)\n",
    "            \n",
    "    return partitions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = TweetRetriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = ret.getTweets('#brexit', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-003871bb2e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-6a1880ff0370>\u001b[0m in \u001b[0;36mget_graph_entities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_graph_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_named_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_event_phrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-6a1880ff0370>\u001b[0m in \u001b[0;36m_get_named_entities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#code for generating named entities of each tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_named_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msegmenter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#code for generating event phrases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3y1s/IRE/IRE_Project/Events_NER/TweetSegmenter.py\u001b[0m in \u001b[0;36mtweet_segmentation\u001b[0;34m(self, json_tweet)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0msegmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mht\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hashtags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# list containing hashtag texts of the tweet text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[0-9]+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remove digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompound_word_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "tweets[0].get_graph_entities()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
