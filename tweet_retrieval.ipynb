{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet Startd\n",
      "BLACK LESBIANS AND BLACK TRANS WOMEN, THIS IS FOR YOU.\n",
      "\n",
      "leave your c*shapps, v*nmos, p*ypals, gofundmes, ko-fis, patreons down below.\n",
      "\n",
      "#transcrowdfund #blacklivesmatter\n",
      "#payblackwomen\n",
      "#blacktranscrowdfund\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "parse() missing 2 required positional arguments: 'api' and 'json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ed1b73fb107d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tweet Ended\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: parse() missing 2 required positional arguments: 'api' and 'json'"
     ]
    }
   ],
   "source": [
    "####input your credentials here\n",
    "consumer_key = '95cMtk1vJvEEW2rlMR0kIU9lE'\n",
    "consumer_secret = 'pMQFi7LBdcudKDNZOokUJGS8mDxQanUv8spxBDdTLiwSZBuUOM'\n",
    "access_token = '1036313393114767360-BZ8Qpi02ghRvehhcITEIyl7SmGWmU6'\n",
    "access_token_secret = 'C7VAqGDhTdB424iBtEwF1CJI9YPTcvNvLjFmaCXENNv3G'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "#####United Airlines\n",
    "# Open/Create a file to append data\n",
    "csvFile = open('ua.csv', 'a')\n",
    "#Use csv Writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for status in tweepy.Cursor(api.search,q=\"#blacklivesmatter\",count=1,tweet_mode = 'extended',\n",
    "                           lang=\"en\",\n",
    "                           since=\"2017-04-03\").items():\n",
    "    print(\"Tweet Startd\")\n",
    "    if hasattr(status, \"retweeted_status\"):  # Check if Retweet\n",
    "        try:\n",
    "            print(status.retweeted_status.extended_tweet[\"full_text\"])\n",
    "        except AttributeError:\n",
    "            print(status.retweeted_status.full_text)\n",
    "    else:\n",
    "        try:\n",
    "            print(status.extended_tweet[\"full_text\"])\n",
    "        except AttributeError:\n",
    "            print(status.full_text)\n",
    "    print(status.parse())\n",
    "    print(\"Tweet Ended\")\n",
    "    #csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet():\n",
    "    \n",
    "    def __init__(self, status_response):\n",
    "        self.id = status_response.id\n",
    "        self._get_text(status_response)\n",
    "        self.user_info = status_response.user\n",
    "        self.entitites = status_response.entities\n",
    "        \n",
    "    def _get_text(self, status):\n",
    "        if hasattr(status, \"retweeted_status\"):  # Check if Retweet\n",
    "            try:\n",
    "                self.text = status.retweeted_status.extended_tweet[\"full_text\"]\n",
    "            except AttributeError:\n",
    "                self.text = status.retweeted_status.full_text\n",
    "        else:\n",
    "            try:\n",
    "                self.text = status.extended_tweet[\"full_text\"]\n",
    "            except AttributeError:\n",
    "                self.text = status.full_text\n",
    "    \n",
    "    #code for generating named entities of each tweet\n",
    "    def _get_named_entities(self):\n",
    "        pass\n",
    "    #code for generating event phrases\n",
    "    def _get_event_phrases(self):\n",
    "        pass\n",
    "    \n",
    "    def get_graph_entities(self)\n",
    "        return self._get_named_entities() + self._get_event_phrases()\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self.id\n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id\n",
    "    \n",
    "class TweetRetriever():\n",
    "    \n",
    "    def __init__(self):\n",
    "        consumer_key = '95cMtk1vJvEEW2rlMR0kIU9lE'\n",
    "        consumer_secret = 'pMQFi7LBdcudKDNZOokUJGS8mDxQanUv8spxBDdTLiwSZBuUOM'\n",
    "        access_token = '1036313393114767360-BZ8Qpi02ghRvehhcITEIyl7SmGWmU6'\n",
    "        access_token_secret = 'C7VAqGDhTdB424iBtEwF1CJI9YPTcvNvLjFmaCXENNv3G'\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self.api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "    \n",
    "    def getTweets(self, hashtag, count = 10):\n",
    "        tweets = []\n",
    "        for status in tweepy.Cursor(self.api.search, q = hashtag, count = count, \n",
    "                                    tweet_mode = 'extended', lang = 'en').items():\n",
    "            tweets.append(Tweet(status))\n",
    "        return tweets\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNode():\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.tweeets = set()\n",
    "        self.value = 0\n",
    "        \n",
    "    def add_tweet(self, tweet):\n",
    "        self.tweeets.add(tweet)\n",
    "    \n",
    "    def common_tweets(self, other):\n",
    "        return len(self.tweeets.intersection(other.tweets))\n",
    "    \n",
    "class TweetGraph():\n",
    "    \n",
    "    def __init__(self, topic):\n",
    "        self.topic = topic\n",
    "        self.nodes = []\n",
    "        self.edge_map = {}\n",
    "        \n",
    "    def add_node(self, node):\n",
    "        self.nodes.append(node)\n",
    "    \n",
    "    def add_edge(self, node1, node2):\n",
    "        assert node1.name in self.node_map\n",
    "        assert node2.name in self.node_map\n",
    "        weight = node1.common_tweets(node2)\n",
    "        self.edge_map.setdefault(node1.name, {}).setdefault(node2.name, weight)\n",
    "        self.edge_map.setdefault(node2.name, {}).setdefault(node1.name, weight)\n",
    "    \n",
    "    def compute_all_edges(self):\n",
    "        for node1 in self.nodes:\n",
    "            for node2 in self.nodes:\n",
    "                self.add_edge(node1, node2)\n",
    "    \n",
    "    def _get_pagerank_matrix(self):\n",
    "        x = [[0 for _ in len(self.nodes)] for _ in len(self.nodes)]\n",
    "        for i, node1 in enumerate(self.nodes):\n",
    "            wsum = 0\n",
    "            for node2 in self.nodes:\n",
    "                wsum += self.edge_map.get(node1.name, {}).get(node2.name, 0)\n",
    "            for j, node2 in enumerate(self.nodes):\n",
    "                x[i][j] = self.edge_map.get(node1.name, {}).get(node2.name, 0)/wsum\n",
    "        return np.array(x)\n",
    "    \n",
    "    def set_textrank_values(self, d = 0.85):\n",
    "        rank_graph = nx.from_numpy_array(self._get_pagerank_matrix())\n",
    "        node_scores = nx.pagerank(rank_graph, aplpha = d)\n",
    "        for n, s in enumerate(node_scores):\n",
    "            self.nodes[n].value = s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = TweetRetriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = ret.getTweets('#worlds2019', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@TeamGriffinLoL vs @G2esports tiebreaker highlights\\U0001f973:\\n\\n3 min GRF FB\\n18 min GRF 3 for 0 mid lane\\n21 min GRF 4 for 2 blue side jungle\\n27 min GRF ACE in base to win\\n\\n#lckwin #Worlds2019'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[1].text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
