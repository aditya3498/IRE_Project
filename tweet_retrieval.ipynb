{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "from Events_NER.TweetSegmenter import SEDTWikSegmenter\n",
    "import pickle\n",
    "from rouge import Rouge \n",
    "import re\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SEDTWik Segmenter\n",
      "SEDTWik Segmenter Ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wiki_titles_file = \"Events_NER/data/final.txt\"\n",
    "segmenter = SEDTWikSegmenter(wiki_titles_file, 4, 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet():\n",
    "    \n",
    "    def __init__(self, status_response):\n",
    "        self.id = status_response.id\n",
    "        self._get_text(status_response)\n",
    "        self.user_info = status_response.user\n",
    "        self.entitites = status_response.entities\n",
    "        self.json = status_response._json\n",
    "        self.json['text'] = self.text\n",
    "        arr = []\n",
    "        for users in self.json['entities']['user_mentions']: \n",
    "            arr += [users['name']]\n",
    "        self.json['entities']['user_mentions'] = arr\n",
    "        arr = []\n",
    "        for users in self.json['entities']['hashtags']: \n",
    "            arr += [users['text']]\n",
    "        self.json['entities']['hashtags'] = arr\n",
    "        \n",
    "    def _get_text(self, status):\n",
    "        if hasattr(status, \"retweeted_status\"):  # Check if Retweet\n",
    "            try:\n",
    "                self.text = status.retweeted_status.extended_tweet[\"full_text\"]\n",
    "            except AttributeError:\n",
    "                self.text = status.retweeted_status.full_text\n",
    "        else:\n",
    "            try:\n",
    "                self.text = status.extended_tweet[\"full_text\"]\n",
    "            except AttributeError:\n",
    "                self.text = status.full_text\n",
    "    \n",
    "    #code for generating named entities of each tweet\n",
    "    def _get_named_entities(self):\n",
    "        ne = segmenter.tweet_segmentation(self.json)\n",
    "        #print(ne)\n",
    "        return ne\n",
    "    \n",
    "        \n",
    "    #code for generating event phrases\n",
    "    def _get_event_phrases(self):\n",
    "        return []\n",
    "    \n",
    "    def get_graph_entities(self):\n",
    "        return self._get_named_entities() + self._get_event_phrases()\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self.id\n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id\n",
    "\n",
    "\n",
    "class TweetRetriever():\n",
    "\n",
    "    def __init__(self):\n",
    "        consumer_key = '95cMtk1vJvEEW2rlMR0kIU9lE'\n",
    "        consumer_secret = 'pMQFi7LBdcudKDNZOokUJGS8mDxQanUv8spxBDdTLiwSZBuUOM'\n",
    "        access_token = '1036313393114767360-BZ8Qpi02ghRvehhcITEIyl7SmGWmU6'\n",
    "        access_token_secret = 'C7VAqGDhTdB424iBtEwF1CJI9YPTcvNvLjFmaCXENNv3G'\n",
    "        auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "        #auth.set_access_token(access_token, access_token_secret)\n",
    "        self.api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify = True)\n",
    "    \n",
    "    def _filterDuplicates(self, tweets):\n",
    "        tweet_text = set()\n",
    "        filtered_tweets = []\n",
    "        for tweet in tweets:\n",
    "            if tweet.text not in tweet_text:\n",
    "                filtered_tweets += [tweet]\n",
    "                tweet_text.add(tweet.text)\n",
    "        return filtered_tweets\n",
    "\n",
    "    def getTweets(self, hashtag, count = 10):\n",
    "        tweets = []\n",
    "        for status in tweepy.Cursor(self.api.search, q = hashtag + \" -filter:retweets\", count = count, tweet_mode = 'extended',\n",
    "                                    lang = 'en',).items():\n",
    "            tweets.append(Tweet(status))\n",
    "        return self._filterDuplicates(tweets)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNode():\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.tweets = set()\n",
    "        self.value = 0\n",
    "        \n",
    "    def add_tweet(self, tweet):\n",
    "        self.tweets.add(tweet)\n",
    "    \n",
    "    def common_tweets(self, other):\n",
    "        return len(self.tweets.intersection(other.tweets))\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name\n",
    "#     def __print__(self):\n",
    "#         print(self.name)\n",
    "    \n",
    "class TweetGraph():\n",
    "    \n",
    "    def __init__(self, topic):\n",
    "        self.topic = topic\n",
    "        self.nodes = {}\n",
    "        self.edge_map = {}\n",
    "        \n",
    "    def add_entity(self, name, tweet_ref):\n",
    "        if name not in self.nodes:\n",
    "            self.nodes[name] = GraphNode(name)\n",
    "        self.nodes[name].add_tweet(tweet_ref)\n",
    "    \n",
    "    def add_edge(self, node1, node2):\n",
    "        assert node1.name in self.nodes\n",
    "        assert node2.name in self.nodes\n",
    "        weight = node1.common_tweets(node2)\n",
    "        self.edge_map.setdefault(node1.name, {}).setdefault(node2.name, weight)\n",
    "        self.edge_map.setdefault(node2.name, {}).setdefault(node1.name, weight)\n",
    "    \n",
    "    def compute_all_edges(self):\n",
    "        for node1 in self.nodes.values():\n",
    "            for node2 in self.nodes.values():\n",
    "                self.add_edge(node1, node2)\n",
    "    \n",
    "    def _get_pagerank_matrix(self):\n",
    "        x = [[0 for _ in range(len(self.nodes))] for _ in range(len(self.nodes))]\n",
    "        for i, node1 in enumerate(self.nodes.values()):\n",
    "            wsum = 0\n",
    "            for node2 in self.nodes.values():\n",
    "                wsum += self.edge_map.get(node1.name, {}).get(node2.name, 0)\n",
    "            for j, node2 in enumerate(self.nodes.values()):\n",
    "                x[i][j] = self.edge_map.get(node1.name, {}).get(node2.name, 0)/wsum\n",
    "        return np.array(x)\n",
    "    \n",
    "    def set_textrank_values(self, d = 0.85):\n",
    "        rank_graph = nx.from_numpy_array(self._get_pagerank_matrix())\n",
    "        node_scores = nx.pagerank(rank_graph, alpha = d)\n",
    "        for i, node in enumerate(self.nodes.values()):\n",
    "            node.value = node_scores[i]\n",
    "    \n",
    "    def get_weight(self, node1, node2):\n",
    "        return self.edge_map.get(node1.name, {}).get(node2.name, 0)\n",
    "    \n",
    "    def get_topic_similarity(self, node):\n",
    "        if node.name in self.topic:\n",
    "            return len(node.tweets)\n",
    "        return 1\n",
    "    \n",
    "    def get_all_node_values(self):\n",
    "        arr = []\n",
    "        for node in self.nodes.values():\n",
    "            arr.append((node.name, node.value))\n",
    "        return sorted(arr, key = lambda x: x[1])\n",
    "    \n",
    "    def get_avg_thres(self):\n",
    "        values = self.get_all_node_values()\n",
    "        return sum([i[1] for i in values])/len(values)\n",
    "        \n",
    "    def get_nodes_above_thres(self, thres = 1):\n",
    "        nodes = []\n",
    "        value_sum = 0\n",
    "        for node in self.nodes.values():\n",
    "            if node.value > thres:\n",
    "                nodes.append(node)\n",
    "                value_sum += node.value\n",
    "        return nodes, value_sum\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraph(topic, tweets):\n",
    "    tweetGraph = TweetGraph(topic)\n",
    "    for tweet in tweets:\n",
    "        graph_entities = tweet.get_graph_entities()\n",
    "        for name in graph_entities:\n",
    "            tweetGraph.add_entity(name, tweet)\n",
    "    tweetGraph.compute_all_edges()\n",
    "    tweetGraph.set_textrank_values()\n",
    "    return tweetGraph\n",
    "\n",
    "def partitionGraph(tweetGraph, alpha, beta, high_rank_thres = 1):\n",
    "    \n",
    "    #initialize highly ranked nodes and their total values sum\n",
    "    high_ranked_nodes, total_value_sum = tweetGraph.get_nodes_above_thres(high_rank_thres)\n",
    "    high_ranked_nodes = sorted(high_ranked_nodes, key = lambda x: x.value)\n",
    "    partitions = []\n",
    "    \n",
    "    #partitioning loop\n",
    "    while len(high_ranked_nodes):\n",
    "        #entity set is the nodes in the partition\n",
    "        entity_set = set()\n",
    "        repr_node = high_ranked_nodes.pop()\n",
    "        entity_set.add(repr_node)\n",
    "        repr_node_topic_similarity = tweetGraph.get_topic_similarity(repr_node)\n",
    "        value_sum = repr_node.value\n",
    "        \n",
    "        for node in high_ranked_nodes:\n",
    "            node_edge_weight = tweetGraph.get_weight(repr_node, node)\n",
    "            node_topic_similarity = tweetGraph.get_topic_similarity(node)\n",
    "            \n",
    "            if node_edge_weight/repr_node_topic_similarity > alpha and \\\n",
    "                node_topic_similarity/repr_node_topic_similarity > alpha:\n",
    "                entity_set.add(node)\n",
    "                value_sum += node.value\n",
    "        \n",
    "        if value_sum/total_value_sum > beta:\n",
    "            temp = []\n",
    "            for node in high_ranked_nodes:\n",
    "                if node not in entity_set:\n",
    "                    temp.append(node)\n",
    "            high_ranked_nodes = temp\n",
    "            \n",
    "            partitions.append([])\n",
    "            for node in list(entity_set):\n",
    "                partitions[-1].append(node)\n",
    "            \n",
    "    return partitions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization(partitions, tweet_cutoff = 1):\n",
    "    summary = []\n",
    "    #print(partitions)\n",
    "    for part in partitions:\n",
    "        tweet_set = set()\n",
    "        for node in part:\n",
    "            tweet_set = tweet_set.union(node.tweets)\n",
    "        node_entity_count = []\n",
    "        tweet_set = list(tweet_set)\n",
    "        #print(tweet_set)\n",
    "        for i, tweet in enumerate(tweet_set):\n",
    "            count = 0\n",
    "            for node in part:\n",
    "                if node.name in tweet.text:\n",
    "                    count += 1\n",
    "            node_entity_count += [(i, count)]\n",
    "        node_entity_count = sorted(node_entity_count, key = lambda x: x[1], reverse = True)\n",
    "        #print(node_entity_count)\n",
    "        for i in range(min(tweet_cutoff, len(tweet_set))):\n",
    "            summary += [tweet_set[node_entity_count[i][0]].text]\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "def createDataset(hashtags, count, json_save_file = None, pickle_loc = None):\n",
    "    \n",
    "    summary_dataset = {}\n",
    "    ret = TweetRetriever()\n",
    "    if json_save_file is not None and os.path.exists(json_save_file):\n",
    "        with open(json_save_file, \"r\") as fp:\n",
    "            summary_dataset = json.load(fp)\n",
    "            \n",
    "    for hasht in hashtags:\n",
    "        \n",
    "        if not os.path.exists(pickle_loc):\n",
    "            os.mkdir(pickle_loc)\n",
    "            \n",
    "        tweets = ret.getTweets(hasht, count)\n",
    "        summary_dataset[hasht] = {\"tweets\": []}\n",
    "        it = 1\n",
    "        for tweet in tweets:\n",
    "            pickle_file_name = hasht + \"_\" + str(it)\n",
    "            print(tweet.text)\n",
    "            summary_dataset[hasht][\"tweets\"].append(tweet.text)\n",
    "            with open(pickle_loc + \"/\" + pickle_file_name, \"wb\") as fp:\n",
    "                pickle.dump(tweet, fp)\n",
    "            it += 1\n",
    "            print(\"=================\")\n",
    "        \n",
    "        print(\"Enter the topic\")\n",
    "        topic = str(input())\n",
    "        print(\"Please Enter User summary\")\n",
    "        user_summary = str(input())\n",
    "        summary_dataset[hasht][\"topic\"] = topic\n",
    "        summary_dataset[hasht][\"user_summary\"] = user_summary\n",
    "        with open(json_save_file, \"w\") as fp:\n",
    "            json.dump(summary_dataset, fp, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpickeledTweets(pickle_dir, hashtag, count):\n",
    "    it = 1\n",
    "    tweets = []\n",
    "    while it < count:\n",
    "        try:\n",
    "            file = pickle_dir + \"/\" + hashtag + \"_\" + str(it)\n",
    "            with open(file, 'rb') as fp:\n",
    "                tweets.append(pickle.load(fp))\n",
    "        except:\n",
    "            raise\n",
    "        it += 1\n",
    "    return tweets\n",
    "                \n",
    "def getRouge1Score(dataset, pickle_dir, alpha, beta, tweets_summary_count, show_scores = False, rouge_thres = 0.5):\n",
    "    \n",
    "    with open(dataset, 'r') as fp:\n",
    "        dataset = json.load(fp)\n",
    "    \n",
    "    score_data = []\n",
    "    for hashtag, data in dataset.items():\n",
    "        tweets = getpickeledTweets(pickle_dir, hashtag, len(data[\"tweets\"]))\n",
    "        topic = data['topic'].split(' ')\n",
    "        try:\n",
    "            graph = createGraph(topic, tweets)\n",
    "        except:\n",
    "            continue\n",
    "        avg = graph.get_avg_thres()\n",
    "        partitions = partitionGraph(graph, alpha, beta, high_rank_thres = avg)\n",
    "        \n",
    "        \n",
    "        psummary = summarization(partitions, tweet_cutoff = tweets_summary_count)\n",
    "        user_summary = data['user_summary']\n",
    "        \n",
    "        summary = ' '.join(psummary)\n",
    "        #print(\"========\")\n",
    "        #print(summary)\n",
    "        summary = re.sub(r'http\\S+', '', summary)\n",
    "        summary = re.sub('[^A-Za-z0-9]+', ' ', summary)\n",
    "        user_summary = re.sub('[^A-Za-z0-9]+', ' ', user_summary)\n",
    "        #print(\"=========\")\n",
    "        #print(summary)\n",
    "        #print(\"=========\")\n",
    "        #print(user_summary)\n",
    "        \n",
    "        rouge = Rouge()\n",
    "        ROUGEscores = rouge.get_scores(summary, user_summary)[0]['rouge-1']['f']\n",
    "        \n",
    "        bleu_summary = summary.split(' ')\n",
    "        bleu_user_summary = user_summary.split(' ')\n",
    "        BLEUscore = nltk.translate.bleu_score.sentence_bleu([bleu_summary], bleu_user_summary, weights = [1])\n",
    "        f1 = 2*(BLEUscore * ROUGEscores) / ( BLEUscore + ROUGEscores)\n",
    "        if show_scores:\n",
    "            print(hashtag, \"\\n\", \"rouge 1 \", ROUGEscores, \" bleu-score \", BLEUscore, \" F1 \", f1)\n",
    "        if ROUGEscores < 0.15: # and ROUGEscores < 0.5:\n",
    "            for tweet in tweets:\n",
    "                print(tweet.text)\n",
    "                print(\"-------------------\")\n",
    "            print(psummary)\n",
    "            print(\"=================\")\n",
    "            \n",
    "        score_data.append(ROUGEscores)\n",
    "    \n",
    "    avg_score = 0\n",
    "    for data in score_data:\n",
    "        avg_score += data\n",
    "    print(avg_score / len(score_data))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def testcode():\n",
    "    for i in np.arange(0,1,0.1):\n",
    "        for j in np.arange(0, 1, 0.1):\n",
    "            print(round(i,2), round(j,2), end = \" \")\n",
    "            try:\n",
    "                getRouge1Score(\"dataset_1.json\", \"Datasets_1\", i, j, 2)\n",
    "            except:\n",
    "                print(\"No output\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-fb99aa68dfa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhashtagset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"#balasahebthackeray\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcreateDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset_3.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Datasets_3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-6f90e8f057c4>\u001b[0m in \u001b[0;36mcreateDataset\u001b[0;34m(hashtags, count, json_save_file, pickle_loc)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0msummary_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasht\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"tweets\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2a76002c3c6c>\u001b[0m in \u001b[0;36mgetTweets\u001b[0;34m(self, hashtag, count)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         for status in tweepy.Cursor(self.api.search, q = hashtag + \" -filter:retweets\", count = count, tweet_mode = 'extended',\n\u001b[0;32m---> 71\u001b[0;31m                                     lang = 'en',).items():\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filterDuplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m                                                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                                                 \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                                                 proxies=self.api.proxy)\n\u001b[0m\u001b[1;32m    190\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTweepError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to send request: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hashtagset = [\"#balasahebthackeray\"]\n",
    "createDataset(hashtagset, 1, \"dataset_3.json\", \"Datasets_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are Reds â¤ï¸we are Liverpool \n",
      "Keep going to the title ğŸ†\n",
      " #LIVMCI\n",
      "-------------------\n",
      "City got comprehensively chowed today in every way. VAR included #LIVMCI\n",
      "-------------------\n",
      "i could jerk this glorious scene off till the end of the days #LFC #LIVMCI https://t.co/H3uqlEYNQ8\n",
      "-------------------\n",
      "I just hope y'all are planning to hand Fabinho the MOTM award straight up! Man's a midfield monster. #LIVMCI\n",
      "-------------------\n",
      "More than anything I was worried about Lovern vs AgÃ¼ero but The croatian was tooo good tonight #LIVMCI\n",
      "-------------------\n",
      "#LIVMCI @ManCity i just wanna say that Aguero performed his worst tonight, he needs to earn game time from now on becoz dat shit waz not acceptable . @aguerosergiokun u disappointed me today man o man ğŸ’”\n",
      "-------------------\n",
      "*plays Anfield Rap on loop all night long*\n",
      "\n",
      "#LIVMCI\n",
      "-------------------\n",
      "I'm not sure what it's called in England, but in Texas, USA... We call it an ass whoopin' #LIVMCI #LiverpoolManchesterCity  #LiverpoolManCity\n",
      "-------------------\n",
      "I only hope this is an omen #YNWA #Liverpool #LIVMCI https://t.co/nYryPSDsdZ\n",
      "-------------------\n",
      "You'll Never Walk Alone ğŸ¤— #LIVMCI\n",
      "-------------------\n",
      "What a guy ğŸ˜ğŸ˜ğŸš€ğŸš€ğŸš€ Pep's head is completely away ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£ #LIVMCI #LiverpoolFC #ManchesterCity #PepGuardiola https://t.co/rbuXqRC37x\n",
      "-------------------\n",
      "I always love it when Pep and Mourinho lose their heads.\n",
      "ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "#LIVMCI\n",
      "-------------------\n",
      "['City got comprehensively chowed today in every way. VAR included #LIVMCI', '#LIVMCI @ManCity i just wanna say that Aguero performed his worst tonight, he needs to earn game time from now on becoz dat shit waz not acceptable . @aguerosergiokun u disappointed me today man o man ğŸ’”', 'We are Reds â¤ï¸we are Liverpool \\nKeep going to the title ğŸ†\\n #LIVMCI', 'I only hope this is an omen #YNWA #Liverpool #LIVMCI https://t.co/nYryPSDsdZ']\n",
      "=================\n",
      "Shit. This is working day lunch time in central. No one can avoid #HKPoliceTerrorist in #HongKong. https://t.co/6RwxuQYGwZ\n",
      "-------------------\n",
      "Cold-blooded people #HongKong. #HongKongProtests https://t.co/2oFQ9e0st4\n",
      "-------------------\n",
      "It's terrible. I really think those cops in the front lines are becoming crazy. They have forgotten their job: to protect citizens, not killing them! \n",
      "#Hongkong #HongKongProstest #StandWithHongKong #FreeHongKong #AntiMaskLaw #HKPoliceTerrorists https://t.co/FqnfCAmwFy\n",
      "-------------------\n",
      "Please we beg you desparately!! It is human crisis here in #HongKong!! https://t.co/hPEhFcPF4R\n",
      "-------------------\n",
      "#HongKong police say heavy objects have been thrown down on their officers today from overpasses, that petrol bombs have been used and that they have responded with rubber bullets and tear gas. Theyâ€™ve appealed for calm. All university classes cancelled, many clash sites. #China\n",
      "-------------------\n",
      "[\"It's terrible. I really think those cops in the front lines are becoming crazy. They have forgotten their job: to protect citizens, not killing them! \\n#Hongkong #HongKongProstest #StandWithHongKong #FreeHongKong #AntiMaskLaw #HKPoliceTerrorists https://t.co/FqnfCAmwFy\"]\n",
      "=================\n",
      "Rigged af but yâ€™all better channel your anger on the cyphers instead on them. If we fight with them weâ€™ll only be called mad or smth like that, itâ€™s no use yâ€™all know itâ€™s rigged. If votes we got those, if charts we got those too. @BTS_twt #ThePeopleChooseBTS #CypherParty https://t.co/kizQ2UQ0QP\n",
      "-------------------\n",
      "K army chart all song\n",
      "Can't i-army chart MIR BWL cypher????\n",
      "Can we use this anger in streaming &amp; buying instead of dragging????\n",
      "I didn't see y'all use anger in  charting song!Â¿\n",
      "\n",
      " â€œ#ARMYsChoiceBTS â€ \n",
      "#CypherParty\n",
      "\n",
      " #ThePeopleChoiceBTS \n",
      "\n",
      "@BTS_twt\n",
      "\n",
      "ğŸ“https://t.co/G4Fmg2OLWM https://t.co/9S3mN6MEot\n",
      "-------------------\n",
      "@Chaotaeic_ @yoomfie YEAH I JUST SAW IMMA RIOT\n",
      "#CYPHERPARTY\n",
      "-------------------\n",
      "Who is ready for a #CypherParty \n",
      "\n",
      "https://t.co/qY4tP1Xu5A\n",
      "-------------------\n",
      "start my day with #CypherParty \n",
      "@BTS_twt \n",
      "https://t.co/P9lHX2EjCF\n",
      "-------------------\n",
      "Hell yeh!!!  #CypherParty\n",
      "https://t.co/HJQs3jWOyq\n",
      "-------------------\n",
      "@dororoann @georgesbryant24 @irenesyves @firejennie @BTS_twt Fine by me... I tried by being absolutely mannered without insults or any sort of aggression. If they fail to see thru that .then well yOlo your reading comprehension needs upgrading. Stream cypher Please #Cypherparty. Join us ğŸ˜„\n",
      "-------------------\n",
      "@fvckendeavor @__gaciria @BTS_twt Count me in!!\n",
      "\n",
      "#CypherParty\n",
      "#ARMYsChoiceBTS\n",
      "@BTS_twt\n",
      "-------------------\n",
      "Letâ€™s get it  #CypherParty\n",
      "-------------------\n",
      "Babies, we're doing #CypherParty &lt;3\n",
      "\n",
      "#ThePeopleChoiceBTS @BTS_twt\n",
      "https://t.co/cC1NSNrSDj\n",
      "-------------------\n",
      "Stream rap line cyphers armys + persona. We projecting  our anger in charts\n",
      "#CypherParty \n",
      "#ARMYsChoiceBTS\n",
      "-------------------\n",
      "goodnight only to @BTS_twt and people who respect bts. pls make sure to stream cyphers 1 2 3 and 4 bwl and mir \n",
      "#CypherParty \n",
      "#ThePeopleChooseBTS https://t.co/O8fBO5f1cf\n",
      "-------------------\n",
      "YES who is up for this!!\n",
      "#CypherParty #ThePeopleChoiceBTS #ARMYsChoiceBTS\n",
      "@BTS_twt\n",
      "\n",
      "https://t.co/U2mikQ1NbD\n",
      "-------------------\n",
      "Someone tell the Peopleâ€™s Clown Awards that Min Yoongi eats whole discographies in under 30 secs.\n",
      "\n",
      "@BTS_twt #BTSStreamingParty #ThePeopleChooseBTS #CypherParty ğŸ”¥ğŸ–¤â›“ğŸ’£ https://t.co/ZCGnPQtTRx\n",
      "-------------------\n",
      "Oh shit weâ€™re trending #ARMYsChoiceBTS ??? Love yall\n",
      "#CypherParty https://t.co/e8jouWLSyy\n",
      "-------------------\n",
      "Having #CypherParty in the middle of the day with my SilverğŸ’ƒ https://t.co/3SAehzk3is\n",
      "-------------------\n",
      "ARMYs are starting #CypherParty letâ€™s get those clout chasing, hypocritical, nasty award show stay pressedt, BTS princes of pop. No cap, just facts. https://t.co/XtT6tytvqh\n",
      "-------------------\n",
      "Let's do this ğŸ¤™\n",
      "#CypherParty @BTS_twt\n",
      "https://t.co/1ekUKazMQf\n",
      "-------------------\n",
      "Yo let's trend #CypherParty ğŸ’œğŸ’œ @BTS_twt \n",
      "#ThePeopleChooseBTS\n",
      "#PCAs\n",
      "#PCAs2019\n",
      "https://t.co/PB7XFGkQDc\n",
      "-------------------\n",
      "Let's go ARMY #CypherParty @BTS_twt https://t.co/z5Obejd64y\n",
      "-------------------\n",
      "Just bought Make It Right again I feel better nowâ˜ºï¸ğŸ’œ \n",
      "I'll also stream some more before finally going to bed it's almost 3 a.m ğŸ˜¬\n",
      "\n",
      "#ARMYsChoiceBTS \n",
      "#ThePeopleChooseBTS \n",
      "#CypherParty \n",
      "@BTS_twt https://t.co/6zoUPeiGLr\n",
      "-------------------\n",
      "Beast mode activatedğŸ’€ğŸ’€ğŸ’€\n",
      "These people ain't scared of us yet?@BTS_twt\n",
      "#ThePeopleChooseBTS\n",
      " https://t.co/NYyeVJTDQr\n",
      "#ThePeopleChoiceBTS \n",
      "#Cypherparty\n",
      "-------------------\n",
      "Stream #CypherParty\n",
      "-------------------\n",
      "#cypherparty everyone?? ğŸ˜\n",
      "\n",
      "#ThePeopleChoiceBTS #ThePeopleChooseBTS \n",
      "#ARMYsChoiceBTS  \n",
      "@BTS_twt\n",
      "-------------------\n",
      "Y'all, if only Ddaeng is available on all paid platforms âœ‹ğŸ˜­\n",
      "#cypherparty\n",
      "-------------------\n",
      "Lets get it \n",
      "#CypherParty #ARMYsChoiceBTS\n",
      "#ThePeopleChooseBTS @BTS_twt\n",
      "\n",
      " https://t.co/sraaCAIwc7\n",
      "-------------------\n",
      "Let's go  Stream  #CypherParty https://t.co/iuQ0LTHuW5\n",
      "-------------------\n",
      "Karmy is  trending â€œ#ARMYsChoiceBTS â€ hastag for BTS now \n",
      "Let's trend this Hastag no one in worldwide &amp; don't forget to stream cypher &amp; MIR \n",
      "#CypherParty\n",
      "\n",
      " #ThePeopleChoiceBTS \n",
      "\n",
      "@BTS_twt\n",
      "\n",
      "https://t.co/G4Fmg2OLWM\n",
      "-------------------\n",
      "['goodnight only to @BTS_twt and people who respect bts. pls make sure to stream cyphers 1 2 3 and 4 bwl and mir \\n#CypherParty \\n#ThePeopleChooseBTS https://t.co/O8fBO5f1cf', 'Rigged af but yâ€™all better channel your anger on the cyphers instead on them. If we fight with them weâ€™ll only be called mad or smth like that, itâ€™s no use yâ€™all know itâ€™s rigged. If votes we got those, if charts we got those too. @BTS_twt #ThePeopleChooseBTS #CypherParty https://t.co/kizQ2UQ0QP', \"K army chart all song\\nCan't i-army chart MIR BWL cypher????\\nCan we use this anger in streaming &amp; buying instead of dragging????\\nI didn't see y'all use anger in  charting song!Â¿\\n\\n â€œ#ARMYsChoiceBTS â€ \\n#CypherParty\\n\\n #ThePeopleChoiceBTS \\n\\n@BTS_twt\\n\\nğŸ“https://t.co/G4Fmg2OLWM https://t.co/9S3mN6MEot\", \"Karmy is  trending â€œ#ARMYsChoiceBTS â€ hastag for BTS now \\nLet's trend this Hastag no one in worldwide &amp; don't forget to stream cypher &amp; MIR \\n#CypherParty\\n\\n #ThePeopleChoiceBTS \\n\\n@BTS_twt\\n\\nhttps://t.co/G4Fmg2OLWM\"]\n",
      "=================\n",
      "I love this guy! Check him out! @tomgrossicomedy ğŸ’šğŸ’› #GoPackGo  https://t.co/BpzQbrwlJV\n",
      "-------------------\n",
      "Sunday Funday ğŸ’šğŸ’› join my Onlyfans to see what I'm wearing under my football gear ğŸ˜˜ğŸ™ˆ #babygirl #camgirl #dm #sexy #Packers #GoPackGo #green #stonerchick #420friendly #420girls #dabs #smokeweedeveryday #SundayFunday #sugarbaby https://t.co/CqYqCYTcQO\n",
      "-------------------\n",
      "Good morning world ğŸ¤™ğŸ˜Š\n",
      "Have a nice #victorymonday ğŸ’šğŸ’›â„ï¸â„ï¸ğŸ˜ğŸ˜ğŸ§€\n",
      "#GoPackGo https://t.co/QssD4PGCQI\n",
      "-------------------\n",
      "@josefkalina @AaronRodgers12 @packers Wohoo Victory Monday! #GoPackGo\n",
      "-------------------\n",
      "@NFLonFOX @packers Hahaha.. ğŸ˜‚ğŸ˜‚ğŸ‘ğŸ’šğŸ’›.. That's funny.. Gotta say it, \"those Cats scared me..\"ğŸ˜±ğŸ˜‚ğŸ˜‚..\n",
      "\n",
      "#GoPackGo ğŸ’—ğŸ’‹ https://t.co/zsTBNZIT4p\n",
      "-------------------\n",
      "The snow came down hella quick in the 4th quarter. ğŸ˜§ğŸ˜±ğŸ˜Ÿ #GoPackGo https://t.co/5kdb6lj0nw\n",
      "-------------------\n",
      "This place is magical ğŸ”®â„ï¸\n",
      "\n",
      "#GoPackGo https://t.co/xgZYcWlMYX\n",
      "-------------------\n",
      "PEAK Packers fan entitlement. Game over. Packers win in a goal line stand! But fans just CANNOT be happy and enjoy the victory. We all get thereâ€™s issues. Rodgers wasnâ€™t â€œdominantâ€, the defense still has holes. But....THEY WON. Gotta stop taking wins for granted. #GoPackGo\n",
      "-------------------\n",
      "My first packers jersey ğŸ˜¬ #GoPackGo ğŸ’šğŸ’› @darnellsavage_ https://t.co/p4GDvv23yB\n",
      "-------------------\n",
      "Going into the bye week 8-2 with a rookie HC when we were written off before the season started is truly the most beautiful thing in the world #GoPackGo\n",
      "-------------------\n",
      "@packers @AaronRodgers12 Winter may be here but weâ€™re #GoPackGo just starting to warm up #packattack\n",
      "-------------------\n",
      "@packers @AaronRodgers12 Nothing better than a Cold Beer and watching the Pack winning in the Snow!!! #GoPackGo\n",
      "-------------------\n",
      "WINter is here! ğŸ¤Ÿâ„ï¸\n",
      "\n",
      "#GoPackGo https://t.co/JWKz5uiFen\n",
      "-------------------\n",
      "Packers win!!!!\n",
      "#GoPackGo\n",
      "-------------------\n",
      "Every #Packers fan getting a follow from me today cuz I'm so excited where we are and where we're going! 8-2 as Matt Lafleur said, \"Don't take this shit for granted\" #GoPackGo #PackersNation\n",
      "-------------------\n",
      "['@packers @AaronRodgers12 Winter may be here but weâ€™re #GoPackGo just starting to warm up #packattack', '@josefkalina @AaronRodgers12 @packers Wohoo Victory Monday! #GoPackGo', '@packers @AaronRodgers12 Nothing better than a Cold Beer and watching the Pack winning in the Snow!!! #GoPackGo', 'My first packers jersey ğŸ˜¬ #GoPackGo ğŸ’šğŸ’› @darnellsavage_ https://t.co/p4GDvv23yB']\n",
      "=================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just finished watching Joker for the second time. I enjoyed it as much as the first time but I noticed more little details. God I hope Joaquin Phoenix wins the Oscar. #Joker #JokerMovie #JokerFilm\n",
      "-------------------\n",
      "Is it just me or is it getting crazier out there?\n",
      "#joker #jokermovie #jokermovie2019 #jokerart https://t.co/xLLFOAb68h\n",
      "-------------------\n",
      "Joker Part 5 is ready to watch via link below, this wraps up this tutorial series ğŸ˜‰ğŸ™ğŸ» thanks again to all who have been watching. \n",
      "\n",
      "https://t.co/OctiIGeXvH\n",
      "\n",
      "#airbrushasylum #airbrushart #joker #joaquinphoenix #videotutorial #learntoairbrush https://t.co/B0F7ALugzD\n",
      "-------------------\n",
      "Careful this is how #joker became a serial killer https://t.co/Q43SqwzAfz\n",
      "-------------------\n",
      "Joker Lollipop at Target #chupachups #joker #batman #dccomics https://t.co/PcqtkB1o03\n",
      "-------------------\n",
      "I got to go see this movie. \n",
      "\n",
      "#JokerMovie #JokerFilm #joker2019 #jokermemes #Joker https://t.co/90KfT1AbCv\n",
      "-------------------\n",
      "sketches \n",
      "#thedarkknight #joker2019 #joker https://t.co/VENdVPbxfV\n",
      "-------------------\n",
      "@my_2bob @MRobertsQLD Your picture is befitting... #mentalhealth of the #Joker\n",
      "-------------------\n",
      "#Joker nears $1 Billion at the WW Box Office.. $985 Million so far..\n",
      "-------------------\n",
      "Why does #Batman only have one worthwhile classic archenemy (#Joker)? Everyone else has been portrayed as a lightweight buffoon, even Two-Face. #Penguin: fuggehdaboutit. The Riddler could be good, though. Imagine if he went all Se7en on Bats? The possibilities are endless.\n",
      "-------------------\n",
      "Joker \n",
      "\n",
      "#joker #heathledger  #joaquinphoenix https://t.co/wmLON18I5p\n",
      "-------------------\n",
      "Saw #Joker for the fifth time today. \n",
      "Euphoric. https://t.co/i9pRMdx4zl\n",
      "-------------------\n",
      "#Joker Week6. SuperHit ğŸ‘ğŸ‘\n",
      "\n",
      "Week1 38.61cr\n",
      "Week2 18.39cr\n",
      "Week3 9.28cr\n",
      "Week4 2.02cr\n",
      "Week5 1.25cr\n",
      "\n",
      "Wknd6 0.26cr\n",
      "Fri 0.07cr\n",
      "Sat 0.09cr\n",
      "Sun 0.10cr\n",
      "\n",
      "Total 69.81cr\n",
      "#PRDMovieReviews\n",
      "-------------------\n",
      "Joker falls short of being a masterpiece. Joaquin phoenix is superb though. Oscar is looming. #joker\n",
      "-------------------\n",
      "Whoa that got dark real fast! #Joker #JokerMovie\n",
      "-------------------\n",
      "**NEW**CARTOON**VIDDY\n",
      "its bout the joker Room. I mean The Joker is relevant right?\n",
      "Subscribe to my youtube channel its all I got left...\n",
      "https://t.co/nsCtk9uHWv\n",
      "\n",
      "#joker #batman #whysoserious #DC #marvelcomics #HarleyQuinn #cartoon #animation #darkdogfilms #crim #feckoff\n",
      "-------------------\n",
      "ğŸ¤¡ Joker ğŸ¤¡\n",
      "\n",
      "\"SOMEONE WHO HIDES BEHIND A MASK.\"\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      "ğŸ¤¡paint @MEHRONmakeupNYC \n",
      "ğŸ¤¡eyeshadow party animal @Laura88Lee \n",
      "ğŸ¤¡lipstick rimmellondonus \n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "#fantasymakeup #joker #clown #mehron en Philadelphia, Pennsylvania https://t.co/aNNnKXGBRa\n",
      "-------------------\n",
      "Me when I'm leaving work tomorrow, and my coworker keeps talking about how good he did in fantasy this week. #Joker #FantasyFootball @shedsports @barstoolsports @CBSFantasy @DraftKings @ESPNFantasy @barstooltweetss https://t.co/QhGW6Yylyd\n",
      "-------------------\n",
      "ğŸ¤¡ Joker ğŸ¤¡\n",
      "\n",
      "\"IS IT JUST ME OR IS IT GETTING CRAZIER OUT THERE?\"\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      "ğŸ¤¡paint @MEHRONmakeupNYC \n",
      "ğŸ¤¡eyeshadow party animal @Laura88Lee \n",
      "ğŸ¤¡lipstick rimmellondonus \n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "#fantasymakeup #joker #clown #mehron enâ€¦ https://t.co/G187nItLnB\n",
      "-------------------\n",
      "Wow....loved #Joker....really hope that #JoaquinPhoenix gets recognized for this role.....so unbelievably Killer...see what I did there?\n",
      "-------------------\n",
      "Watching #Joker https://t.co/9P6XKy5eiY\n",
      "-------------------\n",
      "Watch out boys these Gamer Girls are coming for you! #GameStop #Funko #Joker #Batman #Chase #HelloKitty #MinnieMouse #Gamer #GamerGirls #FunkoPhotography #ToyArt #Kawaii #Photography #GameStop #FreeYourPopsâ€¦ https://t.co/zsdVJQRzSH\n",
      "-------------------\n",
      "Hey @JoelEmbiid &amp; @KarlTowns the joke is on both of you. The Joker is laughing at both of you schooling both of your asses without running his mouth. Well done is better than well said. #Joker #Jokic\n",
      "-------------------\n",
      "#Joker #JokerMovie #Jokerfanart sleep tight https://t.co/Pz4ooTfP9D\n",
      "-------------------\n",
      "#Joker weekend collection in #Australia.\n",
      "$:1.20 M ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\n",
      "#JoaquinPhoenix #JokerMovie #JokerFilm\n",
      "-------------------\n",
      "Worldwide #BoxOffice Update for #Joker:\n",
      "\n",
      "US/Canada: $313.5M\n",
      "UK: $67.7M\n",
      "Mexico: $42.8M\n",
      "Japan: $40.9M\n",
      "France: $39.9M\n",
      "Korea: $37.8M\n",
      "Germany: $35.9M\n",
      "Brazil: $35.1M\n",
      "Italy: $31.4M\n",
      "Russia: $29.6M\n",
      "Spain: $29.5M\n",
      "Australia: $25.3M\n",
      "Indonesia: $13.5M\n",
      "\n",
      "INTL: $671.2M\n",
      "GLOBAL: $984.7M\n",
      "-------------------\n",
      "@wixwaxer @angie_karan Walking dead, eating dead, the #Joker type self destruction amuses quite a few lately. What ever happened to people's spirituality? Or is it all #Hollywood's fault?ğŸ¤”\n",
      "-------------------\n",
      "So @Lyft DEFINITELY about to make me late to #Joker https://t.co/4S9p06LoIl\n",
      "-------------------\n",
      "Aren't we all Jokers? #Joker #JokerMovie\n",
      "-------------------\n",
      "This is how depression really looks like ..\n",
      "#ArthurFleck #Joker #JokerMovie #JoaquinPhoenix https://t.co/7B22s9Lkho\n",
      "-------------------\n",
      "i got inspired by @Whitemar3 and it only seem fit to go all in and put jhin on the sacred pilgrimage, stay tuned and ill animate this entire scene with jhin in 2023\n",
      "\n",
      "#jhin #ArtofLegends #LeagueOfLegends #LeagueOfLegendsFanArt #Joker #jokermovie #jokerstairs https://t.co/GAqixPkSQN\n",
      "-------------------\n",
      "So there are now \"3 Jokers\" with definitive origins\n",
      "Jack Naiper-Batman(1989)\n",
      "Jerome Valeska -Gotham\n",
      "Authur Fleck -Joker (2019)\n",
      "(#dccomics #Joker #Batwoman\n",
      "-------------------\n",
      "Joker\n",
      "\n",
      "Just playing around with some acrylics. Just a first pass on this. Probably do more on it tomorrow. \n",
      "#joker #dccomics #dceu #batman #torontoartist #torontoart #fanart #jokerfanart #acrylicpainting #darkart https://t.co/Y1bSLJZ0lA\n",
      "-------------------\n",
      "#Joker For my whole life, I didnâ€™t know if I even really existed. But I do. And people are starting to notice. https://t.co/CF8UjF5vBk\n",
      "-------------------\n",
      "@therealmavtv what did you think about #Joker ?\n",
      "-------------------\n",
      "apologies for deleting an earlier version of this tweet to the people who liked it, I made a critical mistake and I'm a bit of a perfectionist when it comes to #Joker so I had to redo the tweet. I was distracted, and mid-level distraction is about as distracting as it gets ...\n",
      "-------------------\n",
      "Put On a Happy Face. \n",
      "#Joker #ronburgundy https://t.co/pWIFFgD0h1\n",
      "-------------------\n",
      "['i got inspired by @Whitemar3 and it only seem fit to go all in and put jhin on the sacred pilgrimage, stay tuned and ill animate this entire scene with jhin in 2023\\n\\n#jhin #ArtofLegends #LeagueOfLegends #LeagueOfLegendsFanArt #Joker #jokermovie #jokerstairs https://t.co/GAqixPkSQN', '**NEW**CARTOON**VIDDY\\nits bout the joker Room. I mean The Joker is relevant right?\\nSubscribe to my youtube channel its all I got left...\\nhttps://t.co/nsCtk9uHWv\\n\\n#joker #batman #whysoserious #DC #marvelcomics #HarleyQuinn #cartoon #animation #darkdogfilms #crim #feckoff', 'I got to go see this movie. \\n\\n#JokerMovie #JokerFilm #joker2019 #jokermemes #Joker https://t.co/90KfT1AbCv', 'Joker Lollipop at Target #chupachups #joker #batman #dccomics https://t.co/PcqtkB1o03']\n",
      "=================\n",
      "Congrats To Robert Downey Jr. For The Peopleâ€™s Choice Award For Male Movie Star.\n",
      "...\n",
      "#peopleschoiceawards2019 #robertdowneyjr https://t.co/lQhPoqsH2Y\n",
      "-------------------\n",
      "â€œIâ€™M SO SAD I CRIED WHEN YOU DIED.â€\n",
      "â€œNO, HE DIED. Iâ€™M STILL HERE. THANK YOU FOR YOUR CONDOLENCESâ€\n",
      "\n",
      "WHY IS HE LIKE THIS\n",
      "#RobertDowneyJr #PCAs https://t.co/CoOn7WHja5\n",
      "-------------------\n",
      "Check out movie #homefortheholidays with #hollyhunter and #RobertDowneyJr  amongst a great cast... older movie, it is hilarious!!! Great dialogue. Happy and safe holiday season everyone ğŸ˜\n",
      "-------------------\n",
      "@eonlineasia We love him 3000 #RobertDowneyjr #PCAs #ILoveYou3000\n",
      "-------------------\n",
      "@rdj_Starkster We did it. âœŒğŸ¼ğŸ‘‘ #RobertDowneyjr #TheMaleMovieStar\n",
      "-------------------\n",
      "King deserves ğŸ¥ºâ¤ï¸ #PCAs  #TheMaleMovieStar #RobertDowneyJr https://t.co/vNWCQSfngI\n",
      "-------------------\n",
      "@Crissi40 I'm so happy for him and us. Who voted like crazy people. #RobertDowneyjr #TheMaleMovieStar\n",
      "-------------------\n",
      "Congratulations #RobertDowneyjr #TheMaleMovieStar We did it Ducklings. #AvengersEndgame #Marvel https://t.co/FFNWhY0F3s\n",
      "-------------------\n",
      "My sun.\n",
      "#RobertDowneyJr #PCAs https://t.co/b8dNZQf0fX\n",
      "-------------------\n",
      "Yes Baby Yes !!! #robertdowneyjr https://t.co/KDwaqcViOV\n",
      "-------------------\n",
      "@eentertainment @luvrobertdowney @RobertDowneyJr So happy, we voted like crazy for you my dear. #RobertDowneyjr #TheMaleMovieStar #PCAs âœŒğŸ»\n",
      "-------------------\n",
      "ğŸ˜‚\n",
      ".\n",
      ".\n",
      "Follow @marvelpulse for more â¤ï¸\n",
      ".\n",
      ".\n",
      "#avengers #endgame #avengersendgame #endgamememes #thanos #marvel #marvelmemes #marvelcomics #marvelpulse #avengersmemes #dankmemes #mcu #mcumemes #robertdowneyjr #thanossnapâ€¦ https://t.co/HT0AQ7srKQ\n",
      "-------------------\n",
      "Robert Downey Jr appreciation tweet.\n",
      "\n",
      "Hero. #RobertDowneyJr #IronMan (3) ğŸ˜‹ğŸ˜‹ https://t.co/qWVetGijPH\n",
      "-------------------\n",
      "As a massive RDJ &amp; @Marvel fan, tonight's #PCAs show opener was epic! ğŸ˜±ğŸ™ŒğŸ˜ @peopleschoice robertdowneyjr #robertdowneyjr #LoveYou3000 https://t.co/aGoCgPhbe1\n",
      "-------------------\n",
      "The year of @RobertDowneyJr #robertdowneyjr #PeoplesChoiceAwards #PeopleChoiceAwards ğŸ”¥ https://t.co/A12kkXL0pc\n",
      "-------------------\n",
      "Robert Downey Jr appreciation tweet.\n",
      "\n",
      "Hero. #RobertDowneyJr #IronMan (2) ğŸ˜‹ğŸ˜‹ https://t.co/cxZVzGquS2\n",
      "-------------------\n",
      "Congrats #RobertDowneyJr. ! https://t.co/WEN1xF56HA\n",
      "-------------------\n",
      "As someone who's been outspoken against #RobertDowneyJr winning an #Oscar I'm okay with him winning a PCA. He deserved that\n",
      "-------------------\n",
      "#RobertDowneyJR Won #PCAs Male Movie Star of 2019  Avengers: Endgame \n",
      "Well deserved that movie was the best ğŸ‘ğŸ‘ğŸ†\n",
      "-------------------\n",
      "Robert Downey Jr appreciation tweet.\n",
      "\n",
      "Hero. #RobertDowneyJr #IronMan ğŸ˜‹ğŸ˜‹ https://t.co/1NH4MxkAn7\n",
      "-------------------\n",
      "LOVE YOU 3000 MR STARK!!!! ğŸ˜­â¤ Robert deserves it...  Ugh endgame gave so many feels.. The way we had to say goodbye to iron man tho..  #Pcas #PeopleChoiceAwards #RobertDowneyJr #Ironman https://t.co/ACb2rhhZOZ\n",
      "-------------------\n",
      "Winner The Male Movie Star of 2019\n",
      "ğŸ†#robertdowneyjr #AvengersEndgame #marvel \n",
      "#PCAs #peopleschoice #PeopleChoiceAwards https://t.co/DxnlYya4pL\n",
      "-------------------\n",
      "LOOK AT HIM ğŸ’#RobertDowneyJr #PCAs https://t.co/I2G433m7G9\n",
      "-------------------\n",
      "â€œHE DIED Iâ€™M STILL HERE, THANK YOU FOR YOUR CONDOLENCEâ€\n",
      "\n",
      "I \n",
      "LOVE\n",
      "YOU\n",
      "\n",
      "#RobertDowneyJr #PCAs https://t.co/FbKUtnjpbR\n",
      "-------------------\n",
      "I AM STILL IN CHOC.\n",
      "#RobertDowneyJr #PCAs https://t.co/FZ4noWNmOj\n",
      "-------------------\n",
      "YOU ARE THE MOST BEAUTIFUL AND PRECIOUS PIECE OF ART IN THE UNIVERSE. \n",
      "MY HEART \n",
      "#RobertDowneyJr #PCAs https://t.co/LxBGYh8gza\n",
      "-------------------\n",
      "Follow us @entrepreneur_reborn \n",
      "@robertdowneyjr \n",
      "#entrepreneur_reborn #mondaymotivation #robertdowneyjr #ironman #EntrepreneurReborn #MotivationalQuotes #InspirationalQuotes https://t.co/Q2X5S0vcSw\n",
      "-------------------\n",
      "Robert Downey Jr en los #PCAs #RDJ ğŸ¤©ğŸ¤©ğŸ¤© #RobertDowneyJr Love U https://t.co/kqJ84ZlOCn\n",
      "-------------------\n",
      "Iâ€™m here for it @RobertDowneyJr #peopleschoice #PeopleChoiceAwards #RobertDowneyJr https://t.co/ikBwFbCZo6\n",
      "-------------------\n",
      "['LOVE YOU 3000 MR STARK!!!! ğŸ˜­â¤ Robert deserves it...  Ugh endgame gave so many feels.. The way we had to say goodbye to iron man tho..  #Pcas #PeopleChoiceAwards #RobertDowneyJr #Ironman https://t.co/ACb2rhhZOZ', 'Follow us @entrepreneur_reborn \\n@robertdowneyjr \\n#entrepreneur_reborn #mondaymotivation #robertdowneyjr #ironman #EntrepreneurReborn #MotivationalQuotes #InspirationalQuotes https://t.co/Q2X5S0vcSw', 'ğŸ˜‚\\n.\\n.\\nFollow @marvelpulse for more â¤ï¸\\n.\\n.\\n#avengers #endgame #avengersendgame #endgamememes #thanos #marvel #marvelmemes #marvelcomics #marvelpulse #avengersmemes #dankmemes #mcu #mcumemes #robertdowneyjr #thanossnapâ€¦ https://t.co/HT0AQ7srKQ', '@eentertainment @luvrobertdowney @RobertDowneyJr So happy, we voted like crazy for you my dear. #RobertDowneyjr #TheMaleMovieStar #PCAs âœŒğŸ»']\n",
      "=================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28209525101117444\n"
     ]
    }
   ],
   "source": [
    "getRouge1Score(\"combined_data.json\", \"CDataset\", 0.1, 0.2, 4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = getpickeledTweets(\"CDataset\", \"#RamMandir\", 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = createGraph(['Ram', 'Mandir', 'Ayodhya'], tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thankful', 0.0014586058939796618),\n",
       " ('owaisi', 0.0014626757815777204),\n",
       " ('said', 0.0014626757815777204),\n",
       " ('alms', 0.0014626757815777204),\n",
       " ('we do', 0.0014626757815777208),\n",
       " ('want', 0.0014626757815777208),\n",
       " ('acres', 0.0014626757815777208),\n",
       " ('author', 0.0014689137341255363),\n",
       " ('vote', 0.0014805093788363133),\n",
       " ('eternal', 0.0014805093788363133),\n",
       " ('deity', 0.001494385224682649),\n",
       " ('stood', 0.0015145018129331812),\n",
       " ('ram mandir construction', 0.0015145018129331814),\n",
       " ('arrested', 0.0015151755229324269),\n",
       " ('inflammatory', 0.0015151755229324269),\n",
       " ('social media', 0.0015151755229324269),\n",
       " ('posts', 0.0015151755229324269),\n",
       " ('named', 0.0015521085749999298),\n",
       " ('article 370', 0.0015677977061849483),\n",
       " ('owaisi jailed nowhera', 0.0015737312190643373),\n",
       " ('the reaction', 0.0015823391231062868),\n",
       " ('supporters', 0.0015823391231062868),\n",
       " ('shows', 0.0015823391231062868),\n",
       " ('issue', 0.0015823391231062868),\n",
       " ('thanks to', 0.0015823391231062868),\n",
       " ('impact', 0.0015823391231062868),\n",
       " ('gets', 0.0015903955601126593),\n",
       " ('people of india', 0.0015993917747283027),\n",
       " ('soil', 0.0015993917747283027),\n",
       " ('corner', 0.0015993917747283027),\n",
       " ('india.', 0.0015993917747283027),\n",
       " ('this will be', 0.0015993917747283027),\n",
       " ('the only way', 0.0015993917747283027),\n",
       " ('making it', 0.0015993917747283027),\n",
       " ('who the', 0.0016110682121404062),\n",
       " ('chants', 0.0016110682121404062),\n",
       " ('modi', 0.0016110682121404062),\n",
       " ('ram janmabhoomi', 0.0016110682121404062),\n",
       " ('station', 0.0016134536656703335),\n",
       " ('uniform civil code', 0.0016134536656703335),\n",
       " ('agla', 0.0016134536656703335),\n",
       " ('big decisions', 0.0016150322108732845),\n",
       " ('narendra modi government', 0.0016150322108732847),\n",
       " ('changed', 0.0016150322108732847),\n",
       " ('national', 0.0016205952753578945),\n",
       " ('neelam pandey', 0.0016205952753578945),\n",
       " ('votes', 0.0016205952753578948),\n",
       " ('shekhar gupta', 0.0016205952753578948),\n",
       " ('moushumi das gupta', 0.0016205952753578948),\n",
       " ('accepted', 0.00162146461230073),\n",
       " ('litigant', 0.00162146461230073),\n",
       " ('muslims', 0.00162146461230073),\n",
       " ('iqbal ansari', 0.00162146461230073),\n",
       " ('ayodhya judgment', 0.00162146461230073),\n",
       " ('pooja', 0.001627101418155391),\n",
       " ('shri ram', 0.001627101418155391),\n",
       " ('haters', 0.0016293207216728168),\n",
       " ('fake', 0.0016293207216728168),\n",
       " ('tweet', 0.001629320721672817),\n",
       " ('tejashwi yadav', 0.001629320721672817),\n",
       " ('the cleric', 0.0016381288387942072),\n",
       " ('knew', 0.0016381288387942072),\n",
       " ('be in', 0.0016381288387942072),\n",
       " ('favour', 0.0016381288387942072),\n",
       " ('fix', 0.0016381288387942075),\n",
       " ('the court', 0.0016381288387942075),\n",
       " ('rules', 0.0016381288387942075),\n",
       " ('the laws', 0.0016435096550498338),\n",
       " ('mondaythoughts', 0.0016435096550498338),\n",
       " ('religiÃ³n', 0.0016435096550498338),\n",
       " ('religious freedom', 0.0016435096550498338),\n",
       " ('buddhism', 0.0016435096550498338),\n",
       " ('worshipping', 0.001643509655049834),\n",
       " ('gods', 0.001643509655049834),\n",
       " ('obedience', 0.001643509655049834),\n",
       " ('questioned', 0.0016460448597223737),\n",
       " ('the left', 0.0016489600601366995),\n",
       " ('reclaiming', 0.0016489600601366995),\n",
       " ('second', 0.0016489600601366995),\n",
       " ('breakingnews', 0.0016495178827800419),\n",
       " ('justice for babri masjid', 0.0016495178827800419),\n",
       " ('ram mandir fund', 0.0016495178827800419),\n",
       " ('mandirwahinbanega', 0.0016495178827800419),\n",
       " ('mandir wahin banayenge', 0.0016495178827800419),\n",
       " ('accept', 0.0016559400827860452),\n",
       " ('maulana', 0.0016559400827860452),\n",
       " ('arshad', 0.0016559400827860452),\n",
       " ('jamiat ulema-e-hind', 0.0016559400827860452),\n",
       " ('news alert', 0.0016559400827860452),\n",
       " ('supreme courtof india', 0.0016559400827860452),\n",
       " ('head', 0.0016559400827860454),\n",
       " ('oic', 0.0016559400827860454),\n",
       " ('ashraf madani', 0.0016559400827860454),\n",
       " ('hope', 0.0016562088172068716),\n",
       " ('brings', 0.0016562088172068716),\n",
       " ('historic', 0.0016562088172068716),\n",
       " ('youths', 0.0016562088172068718),\n",
       " ('tell', 0.0016562088172068718),\n",
       " ('tourism', 0.0016562088172068718),\n",
       " ('peace', 0.0016562088172068718),\n",
       " ('asmita nandy', 0.0016562088172068718),\n",
       " ('for life', 0.0016564195249429091),\n",
       " ('lives', 0.0016564195249429091),\n",
       " ('coming', 0.0016564195249429091),\n",
       " ('guruji', 0.0016564195249429091),\n",
       " ('khalsa', 0.0016564195249429091),\n",
       " ('rss', 0.0016564195249429091),\n",
       " ('raylon quadros', 0.0016564195249429091),\n",
       " ('manuru srinivas', 0.0016564195249429091),\n",
       " ('rana', 0.0016570032705021172),\n",
       " ('jai shree ram', 0.0016587576106664305),\n",
       " ('javed akhtar', 0.001658939830393798),\n",
       " ('leading counsel', 0.0016627142645357907),\n",
       " ('sc.', 0.0016627142645357907),\n",
       " ('ram lalla', 0.0016627142645357909),\n",
       " ('shree', 0.0016627142645357909),\n",
       " ('modi governmnet', 0.0016634757012374897),\n",
       " ('divorcecourt', 0.0016634757012374897),\n",
       " ('government', 0.0016634757012374897),\n",
       " ('disaster', 0.0016634757012374897),\n",
       " ('rubika liyaquat', 0.001667337132136124),\n",
       " ('anti', 0.0016720367227473006),\n",
       " ('terror', 0.0016720367227473006),\n",
       " ('works', 0.0016722534608838594),\n",
       " ('this is how', 0.0016722534608838594),\n",
       " ('team', 0.0016722534608838594),\n",
       " ('welcome', 0.0016722534608838594),\n",
       " ('distribution', 0.0016722534608838596),\n",
       " ('bhajan', 0.0016722534608838598),\n",
       " ('journey', 0.0016722534608838598),\n",
       " ('ram janmabhoomi movement', 0.0016722534608838598),\n",
       " ('signage', 0.0016745625616284194),\n",
       " ('siege', 0.0016745625616284194),\n",
       " ('the opportunity', 0.0016745625616284194),\n",
       " ('produce', 0.001675405026525368),\n",
       " ('birth certificate', 0.001675405026525368),\n",
       " ('the nationwantstoknow', 0.0016791175965872834),\n",
       " ('bhakts', 0.0016791175965872834),\n",
       " ('christianity', 0.0016803990243848535),\n",
       " ('religions', 0.0016803990243848535),\n",
       " ('love', 0.0016803990243848535),\n",
       " ('jew', 0.0016803990243848537),\n",
       " ('peace and love', 0.0016803990243848537),\n",
       " ('go to', 0.0016899013309371002),\n",
       " ('namo d', 0.0016899013309371002),\n",
       " ('watch', 0.0016899013309371004),\n",
       " ('speeches', 0.0016899013309371004),\n",
       " ('in 3d', 0.0016899013309371004),\n",
       " ('bjp noida mahanagar', 0.0016899013309371004),\n",
       " ('modi hai to mumkin hai', 0.0016899013309371004),\n",
       " ('prime minister', 0.0016899013309371006),\n",
       " ('narendra', 0.0016899013309371006),\n",
       " ('address', 0.0016899013309371006),\n",
       " ('the nation', 0.0016899013309371006),\n",
       " ('lucky', 0.001691489554111106),\n",
       " ('arms', 0.001691489554111106),\n",
       " ('rj raunac', 0.001691489554111106),\n",
       " ('à¤°à¤¾à¤® à¤¸à¤¤à¥à¤¯ à¤¹à¥ˆà¤‚ à¤°à¤¾à¤® à¤¹à¥€ à¤¸à¤¾à¤•à¥à¤·à¥€', 0.001691489554111106),\n",
       " ('azad maidan', 0.001691891414070866),\n",
       " ('type', 0.001691891414070866),\n",
       " ('riots', 0.001691891414070866),\n",
       " ('short time', 0.001691891414070866),\n",
       " ('bomb', 0.001691891414070866),\n",
       " ('26/11', 0.001691891414070866),\n",
       " ('attacks', 0.001691891414070866),\n",
       " ('long', 0.001691891414070866),\n",
       " ('media room', 0.001691891414070866),\n",
       " ('ashutosh', 0.0016935195711718265),\n",
       " ('param', 0.0016951286635300449),\n",
       " ('sarsanghachalak', 0.0016951286635300449),\n",
       " ('suresh joshi', 0.0016951286635300449),\n",
       " ('met', 0.0016951286635300449),\n",
       " ('of age', 0.0016951286635300449),\n",
       " ('has been', 0.0016951286635300449),\n",
       " ('fighting', 0.0016951286635300449),\n",
       " ('the case', 0.0016951286635300449),\n",
       " ('past', 0.0016951286635300449),\n",
       " ('40 years', 0.0016951286635300449),\n",
       " ('gratitude', 0.0016951286635300449),\n",
       " ('mohan bhagwat', 0.0016951286635300449),\n",
       " ('incentivize', 0.0017022397641745888),\n",
       " ('similar', 0.0017022397641745888),\n",
       " ('a 5', 0.0017022397641745888),\n",
       " ('min', 0.0017022397641745888),\n",
       " ('exciting', 0.0017022397641745888),\n",
       " ('adventurous', 0.0017022397641745888),\n",
       " ('yogi adityanath', 0.0017022397641745888),\n",
       " ('the ride d', 0.0017022397641745888),\n",
       " ('universal studios', 0.0017022397641745888),\n",
       " ('millennial', 0.001702239764174589),\n",
       " ('kids', 0.001702239764174589),\n",
       " ('to come', 0.001702239764174589),\n",
       " ('plan', 0.001702239764174589),\n",
       " ('having', 0.0017037549003208507),\n",
       " ('following', 0.0017037549003208507),\n",
       " ('the right', 0.0017037549003208507),\n",
       " ('kashmir', 0.0017037549003208507),\n",
       " ('indigenous people', 0.0017037549003208509),\n",
       " ('killed', 0.0017037549003208509),\n",
       " ('the time', 0.0017037549003208509),\n",
       " ('buddha', 0.0017037549003208509),\n",
       " ('islam', 0.0017037549003208509),\n",
       " ('100%', 0.0017041367454644495),\n",
       " ('in struggle', 0.0017041367454644495),\n",
       " ('ayodha verdict', 0.0017041367454644495),\n",
       " ('involved', 0.0017041367454644497),\n",
       " ('phase', 0.0017041367454644497),\n",
       " ('build', 0.001704245176812386),\n",
       " ('reaching', 0.001704245176812386),\n",
       " ('peak', 0.001704245176812386),\n",
       " ('shivsena', 0.001704245176812386),\n",
       " ('balasahebthackeray', 0.001704245176812386),\n",
       " ('it was', 0.0017042451768123862),\n",
       " ('1989', 0.0017042451768123862),\n",
       " ('decided', 0.0017042451768123862),\n",
       " ('party', 0.0017042451768123862),\n",
       " ('alliance', 0.0017042451768123862),\n",
       " ('partner', 0.0017042451768123862),\n",
       " ('that time', 0.0017042451768123862),\n",
       " ('the movement', 0.0017042451768123862),\n",
       " ('despite', 0.0017060495000396603),\n",
       " ('dominated', 0.0017060495000396603),\n",
       " (\"that's\", 0.0017060495000396603),\n",
       " ('morning', 0.0017060495000396606),\n",
       " ('gym', 0.0017060495000396606),\n",
       " ('happy', 0.0017060495000396606),\n",
       " ('a single life', 0.0017060495000396606),\n",
       " ('issues', 0.0017060495000396606),\n",
       " ('politics', 0.0017060495000396606),\n",
       " ('today', 0.0017060495000396608),\n",
       " ('discussing', 0.0017060495000396608),\n",
       " ('with friends', 0.0017060495000396608),\n",
       " ('local', 0.0017060495000396608),\n",
       " ('there is more', 0.0017069580943008076),\n",
       " ('form', 0.0017078652525264557),\n",
       " ('govt.', 0.0017078652525264557),\n",
       " ('post', 0.001707865252526456),\n",
       " ('chance', 0.001707865252526456),\n",
       " ('sanjay nirupam', 0.001707865252526456),\n",
       " ('the best', 0.0017078652525264562),\n",
       " ('serve the people', 0.0017078652525264562),\n",
       " ('leena', 0.0017078652525264562),\n",
       " ('namo bharath', 0.0017099557244736978),\n",
       " ('hindustan times', 0.0017104972621521351),\n",
       " ('the most', 0.0017111717841103969),\n",
       " ('thing', 0.0017111717841103969),\n",
       " ('is to', 0.0017111717841103969),\n",
       " ('ensure', 0.0017111717841103969),\n",
       " ('perpetuity', 0.0017111717841103969),\n",
       " ('the trust', 0.0017111717841103969),\n",
       " ('administration', 0.0017111717841103969),\n",
       " ('employees', 0.0017111717841103969),\n",
       " ('mere', 0.0017111717841103969),\n",
       " ('we will', 0.0017111717841103969),\n",
       " ('situation', 0.0017111717841103969),\n",
       " ('tirupati', 0.0017111717841103969),\n",
       " ('kerala', 0.0017111717841103969),\n",
       " ('vadiraj c s', 0.0017111717841103969),\n",
       " ('mediacrooks', 0.0017111717841103969),\n",
       " ('ayodhya case', 0.0017111842257142569),\n",
       " ('babri mosque', 0.001711184225714257),\n",
       " ('blessings', 0.0017135958568843795),\n",
       " ('lord rama', 0.0017135958568843795),\n",
       " ('architect', 0.0017135958568843795),\n",
       " ('cum', 0.0017135958568843797),\n",
       " ('sculptor', 0.0017135958568843797),\n",
       " ('pt.', 0.0017135958568843797),\n",
       " ('rajya sabha mp', 0.0017135958568843797),\n",
       " ('adwaita', 0.0017135958568843797),\n",
       " ('the director', 0.0017135958568843797),\n",
       " ('appears', 0.0017135958568843797),\n",
       " ('destined', 0.0017135958568843797),\n",
       " ('raghunath mohapatra', 0.00171359585688438),\n",
       " ('going', 0.001714147127310057),\n",
       " ('ahead', 0.001714147127310057),\n",
       " ('better', 0.001714147127310057),\n",
       " ('dalit', 0.001714147127310057),\n",
       " ('kaushal panwarfor head priest', 0.001714147127310057),\n",
       " ('merger', 0.0017218885664058692),\n",
       " ('pocso', 0.0017218885664058692),\n",
       " ('motor vehicle', 0.0017218885664058692),\n",
       " ('2nd', 0.0017218885664058692),\n",
       " ('banks', 0.0017218885664058694),\n",
       " ('amendment', 0.0017218885664058694),\n",
       " ('act', 0.0017218885664058694),\n",
       " ('stupid', 0.0017255931852599915),\n",
       " ('statement', 0.0017255931852599915),\n",
       " ('intelligent', 0.0017255931852599915),\n",
       " ('political', 0.0017255931852599915),\n",
       " ('advani', 0.0017255931852599915),\n",
       " ('laws', 0.0017255931852599915),\n",
       " ('hand', 0.0017255931852599915),\n",
       " (\"doesn't\", 0.0017255931852599915),\n",
       " ('harami', 0.0017255931852599915),\n",
       " ('the existence', 0.0017255931852599917),\n",
       " ('centuries', 0.0017255931852599917),\n",
       " ('ram janmbhoomi', 0.0017277177864379256),\n",
       " ('ram mandir verdict', 0.0017277177864379256),\n",
       " ('money', 0.0017326234698739058),\n",
       " ('you want', 0.0017326234698739058),\n",
       " ('with u', 0.0017326234698739058),\n",
       " ('suffered', 0.0017326234698739058),\n",
       " ('rejoicing', 0.001732623469873906),\n",
       " ('offering', 0.001732623469873906),\n",
       " ('constructing', 0.001732623469873906),\n",
       " ('wrong', 0.001732623469873906),\n",
       " (\"haven't\", 0.001732623469873906),\n",
       " ('flying', 0.001734429526234568),\n",
       " ('angels', 0.001734429526234568),\n",
       " ('delivering', 0.001734429526234568),\n",
       " ('sex education', 0.001734429526234568),\n",
       " ('illiterate', 0.001734429526234568),\n",
       " ('nomads', 0.001734429526234568),\n",
       " ('mahatma gandhi', 0.001734429526234568),\n",
       " ('revenge', 0.0017349515928312773),\n",
       " ('demolition', 0.0017349515928312773),\n",
       " ('blast', 0.0017349515928312775),\n",
       " ('blamed', 0.0017349515928312775),\n",
       " ('the witnesses', 0.0017379058859386723),\n",
       " ('deposed', 0.0017379058859386723),\n",
       " ('basis', 0.0017379058859386723),\n",
       " ('islamic', 0.001737937814086111),\n",
       " ('babur', 0.001737937814086111),\n",
       " ('invader', 0.0017379378140861112),\n",
       " ('chandrakant sompura', 0.0017417760386270538),\n",
       " ('(2)', 0.0017431425153832533),\n",
       " ('ban on', 0.0017431425153832533),\n",
       " ('internet', 0.0017431425153832533),\n",
       " ('manner', 0.0017431425153832533),\n",
       " ('hanuman mandir', 0.0017434685173524788),\n",
       " ('crores', 0.0017434685173524788),\n",
       " ('free', 0.0017434685173524788),\n",
       " ('food', 0.0017434685173524788),\n",
       " ('langer', 0.0017434685173524788),\n",
       " ('run', 0.0017434685173524788),\n",
       " ('devotees', 0.0017434685173524788),\n",
       " ('round', 0.0017434685173524788),\n",
       " ('mindset', 0.0017500579159757433),\n",
       " ('those people', 0.0017500579159757433),\n",
       " ('baqi', 0.0017500579159757433),\n",
       " ('1528', 0.0017500579159757433),\n",
       " ('ndtv', 0.0017500579159757433),\n",
       " ('demolished', 0.0017500579159757436),\n",
       " ('farhana', 0.0017500579159757436),\n",
       " ('pivotal', 0.0017551973065439103),\n",
       " ('rana ayyub', 0.001756566039854572),\n",
       " ('the verdict', 0.0017565660398545723),\n",
       " ('evident', 0.0017583280353620544),\n",
       " ('gyanvapi', 0.0017583280353620544),\n",
       " ('kashi vishwanath', 0.0017583280353620544),\n",
       " ('this is', 0.0017583280353620546),\n",
       " ('the walls', 0.0017583280353620546),\n",
       " ('aurangzeb', 0.0017583280353620546),\n",
       " ('asaduddin owaisi', 0.0017587244809789257),\n",
       " ('communal', 0.0017640187062923254),\n",
       " ('frenzy', 0.0017640187062923254),\n",
       " ('in the name of', 0.0017640187062923254),\n",
       " ('enforcing', 0.0017640187062923254),\n",
       " ('justice?', 0.0017640187062923254),\n",
       " ('it.', 0.0017640187062923254),\n",
       " ('1 may', 0.0017640187062923254),\n",
       " ('justices', 0.0017640187062923254),\n",
       " ('majoritarian', 0.0017640187062923254),\n",
       " ('the ultimate solution', 0.0017640187062923254),\n",
       " ('prashant bhushan', 0.0017640187062923254),\n",
       " ('case', 0.0017689511187397816),\n",
       " ('the start', 0.0017689511187397816),\n",
       " ('predecessor', 0.0017689511187397816),\n",
       " ('dipak misra', 0.0017689511187397816),\n",
       " ('kept', 0.0017689511187397816),\n",
       " ('the first', 0.0017689511187397816),\n",
       " ('pushed', 0.0017689511187397816),\n",
       " ('priority', 0.0017689511187397818),\n",
       " ('instance', 0.0017689511187397818),\n",
       " ('the cold', 0.0017689511187397818),\n",
       " ('learn', 0.0017752981339230508),\n",
       " ('how to', 0.0017752981339230508),\n",
       " ('victim', 0.0017752981339230508),\n",
       " ('country', 0.0017752981339230508),\n",
       " ('donated', 0.0017752981339230508),\n",
       " ('created', 0.0017752981339230508),\n",
       " ('card', 0.001775298133923051),\n",
       " ('we are', 0.001775298133923051),\n",
       " ('the only', 0.001775298133923051),\n",
       " ('in the world', 0.001775298133923051),\n",
       " ('land', 0.001775298133923051),\n",
       " ('turned out', 0.001775298133923051),\n",
       " ('dont', 0.0017830856691466142),\n",
       " ('have to', 0.0017830856691466142),\n",
       " ('carry', 0.0017830856691466142),\n",
       " ('banning', 0.0017830856691466144),\n",
       " ('the social', 0.0017830856691466144),\n",
       " ('networking', 0.0017830856691466144),\n",
       " ('sites', 0.0017830856691466144),\n",
       " ('the people', 0.0017830856691466144),\n",
       " ('suffer', 0.0017830856691466144),\n",
       " ('mota bhai', 0.0017990937822736322),\n",
       " ('master stroke', 0.0017990937822736325),\n",
       " ('client', 0.0018024305940265756),\n",
       " ('splendid', 0.0018024305940265756),\n",
       " ('collection', 0.0018024305940265756),\n",
       " ('well known', 0.0018024305940265756),\n",
       " ('excellent', 0.0018024305940265756),\n",
       " ('finishing', 0.0018024305940265756),\n",
       " ('marble', 0.0018024305940265756),\n",
       " ('moortiart', 0.0018024305940265756),\n",
       " ('italy', 0.0018024305940265756),\n",
       " ('australia', 0.0018024305940265756),\n",
       " ('belgium', 0.0018024305940265756),\n",
       " ('hawaii', 0.0018024305940265756),\n",
       " ('malaysia', 0.0018024305940265756),\n",
       " ('denmark', 0.0018024305940265756),\n",
       " ('america', 0.0018024305940265756),\n",
       " ('toronto', 0.0018024305940265756),\n",
       " ('europe', 0.0018024305940265756),\n",
       " ('austria', 0.0018024305940265756),\n",
       " ('statue', 0.0018024305940265758),\n",
       " ('ramakrishna paramhansa', 0.0018024305940265758),\n",
       " ('pure', 0.0018024305940265758),\n",
       " ('white', 0.0018024305940265758),\n",
       " ('offer', 0.0018024305940265758),\n",
       " ('@amazon', 0.001815607881041005),\n",
       " ('amazon', 0.001815607881041005),\n",
       " ('stop', 0.001815607881041005),\n",
       " ('making', 0.001815607881041005),\n",
       " ('fool', 0.001815607881041005),\n",
       " ('chek', 0.001815607881041005),\n",
       " ('the photos', 0.001815607881041005),\n",
       " ('talked', 0.001815607881041005),\n",
       " (\"don't\", 0.001815607881041005),\n",
       " ('ordered', 0.001815607881041005),\n",
       " ('pieces', 0.001815607881041005),\n",
       " ('amazon help', 0.001815607881041005),\n",
       " ('amazon prime video us', 0.001815607881041005),\n",
       " ('customer care', 0.0018156078810410052),\n",
       " ('agree', 0.0018156078810410052),\n",
       " ('the pack', 0.0018156078810410052),\n",
       " ('jeggings', 0.0018156078810410052),\n",
       " ('amazoncom', 0.0018156078810410052),\n",
       " ('seriously', 0.0018156078810410052),\n",
       " ('ravi shankar prasad', 0.001821068385072185),\n",
       " ('digital india', 0.001821068385072185),\n",
       " ('digital transformation', 0.001821068385072185),\n",
       " ('there is', 0.0018233346562558043),\n",
       " ('doubt', 0.0018233346562558043),\n",
       " ('supremecourt', 0.0018233346562558043),\n",
       " ('sabrimala', 0.0018233346562558043),\n",
       " ('the rest', 0.0018413989427571225),\n",
       " (\"that's all folks!\", 0.0018413989427571225),\n",
       " ('the world', 0.0018413989427571228),\n",
       " ('remember', 0.0018623450304172237),\n",
       " ('jai shri ram', 0.0018761838590818237),\n",
       " ('babrimasjid', 0.001899493227984187),\n",
       " ('monday motivation', 0.0019865971399085245),\n",
       " ('modi haito mumkin hai', 0.0020113311246357686),\n",
       " ('till', 0.0020158147758897703),\n",
       " ('babri masjid case', 0.0020817282679661854),\n",
       " ('support', 0.002128114638515676),\n",
       " ('ram', 0.002133983057443174),\n",
       " ('important', 0.0021393202473320226),\n",
       " ('i will', 0.002226320716533479),\n",
       " ('is not', 0.0022321528117059094),\n",
       " ('rammandir', 0.0022508577177522025),\n",
       " ('justice', 0.0022775142449559093),\n",
       " ('old', 0.002309545176385053),\n",
       " ('news', 0.002309971293110473),\n",
       " ('role', 0.002325815620850867),\n",
       " ('people', 0.002340498471784992),\n",
       " ('advocate', 0.0023488178561683706),\n",
       " ('years', 0.0023488178561683706),\n",
       " ('who is', 0.0023488178561683706),\n",
       " ('justify', 0.0023543993982177496),\n",
       " ('built', 0.002383044890143458),\n",
       " ('mosque', 0.0023830448901434585),\n",
       " ('to be', 0.0023893090146189055),\n",
       " ('huge', 0.0023956676426054434),\n",
       " ('prabhu', 0.0024217794052739322),\n",
       " ('pmo india', 0.002434924615109717),\n",
       " ('ram temple', 0.0024573731357839055),\n",
       " ('hindus', 0.0024786472359445027),\n",
       " ('sikh', 0.002498853536753859),\n",
       " ('play', 0.0025053032364019874),\n",
       " ('taking', 0.002515792453062858),\n",
       " ('video', 0.002526828731065734),\n",
       " ('temple', 0.0025467131824621477),\n",
       " ('triple talaq', 0.002547547049808064),\n",
       " ('shri', 0.0025608678873642195),\n",
       " ('amit shah', 0.002581215530665322),\n",
       " ('babri', 0.0025941539843451376),\n",
       " ('congress', 0.0026475560503443248),\n",
       " ('law', 0.0026979129321108935),\n",
       " ('like', 0.0027359993353083807),\n",
       " ('mandir', 0.0027512668023258503),\n",
       " ('taken', 0.0027593802341492574),\n",
       " ('belief', 0.002788003872319617),\n",
       " ('veblr', 0.002825352013800462),\n",
       " ('ram mandir in ayodhya', 0.0028926399479682198),\n",
       " ('babri masjidverdict', 0.002930342223390386),\n",
       " ('want to', 0.0029559950626893987),\n",
       " ('here is', 0.0029629420322523515),\n",
       " ('babri masjid', 0.002997154249647532),\n",
       " ('article', 0.003098675092035782),\n",
       " ('hindu', 0.00316314438309781),\n",
       " ('construction', 0.0032002151172697735),\n",
       " ('@narendramodi', 0.003656425666657732),\n",
       " ('muslim', 0.0038923790868927426),\n",
       " ('india', 0.004020582993038911),\n",
       " ('bjp', 0.004679236322542542),\n",
       " ('verdict', 0.0057396420305548855),\n",
       " ('narendra modi', 0.006479858673199649),\n",
       " ('ayodhyaverdict', 0.009304766932975968),\n",
       " ('ayodhya', 0.01431495988751202),\n",
       " ('ram mandir', 0.04817179066260198)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_all_node_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
